# ============================================
# AI GROWTH PLANNER - ENVIRONMENT CONFIGURATION
# ============================================
# Copy this file to .env and fill in your actual values
# For detailed setup instructions, see: backend/ENV_SETUP_GUIDE.md

# ============================================
# DATABASE CONFIGURATION (PostgreSQL)
# ============================================
# Host where PostgreSQL is running
DATABASE_HOST=localhost

# PostgreSQL port (default 5432)
DATABASE_PORT=5432

# PostgreSQL username
DATABASE_USERNAME=postgres

# PostgreSQL password
DATABASE_PASSWORD=postgres

# Database name to create/use
DATABASE_NAME=ai_growth_planner

# ============================================
# SERVER CONFIGURATION
# ============================================
# Port for the NestJS server (default 3000)
PORT=3000

# Environment: development, staging, production
NODE_ENV=development

# ============================================
# AI PROVIDER CONFIGURATION
# ============================================
# IMPORTANT: Choose ONE provider below
# Valid options: 'openai', 'openrouter', 'ollama'
# 
# - openai: Use OpenAI directly (requires paid API key)
# - openrouter: Use OpenRouter (supports 200+ models, more affordable)
# - ollama: Use local Ollama instance (free, runs locally)
AI_PROVIDER=openrouter

# ============================================
# OPENAI CONFIGURATION
# ============================================
# Only required if AI_PROVIDER=openai
# 
# 1. Get your API key from: https://platform.openai.com/api-keys
# 2. API key format: sk-proj-xxxxxxxxxxxxx
# 3. Sign up for paid account and add billing method
#
# ‚ö†Ô∏è  Note: Free trial credits expire after 3 months
# üí∞ Costs vary by model (GPT-4 ~$0.03/1K input tokens)

# Your OpenAI API key
OPENAI_API_KEY=sk-proj-YOUR_OPENAI_API_KEY_HERE

# Available models:
# - gpt-4-turbo: Most capable, best for complex tasks (~$0.01/1K tokens)
# - gpt-4: Slightly slower but same capability (~$0.03/1K tokens)
# - gpt-3.5-turbo: Fast and cheap (~$0.0005/1K tokens)
OPENAI_MODEL=gpt-4-turbo

# ============================================
# OPENROUTER CONFIGURATION (RECOMMENDED)
# ============================================
# Only required if AI_PROVIDER=openrouter
#
# OpenRouter provides unified API access to 200+ models:
# - OpenAI models (GPT-4, GPT-3.5)
# - Claude (Anthropic)
# - Mistral, Llama, and more
#
# 1. Sign up: https://openrouter.ai
# 2. Get API key: https://openrouter.ai/keys
# 3. Models list: https://openrouter.ai/docs#models
#
# üí∞ Free tier available with 100 requests/month
# üí≥ Pricing: Similar to direct API, no markup
# ‚ú® Benefits: Try multiple models, lower costs, no signup requirements per model

# Your OpenRouter API key (format: sk-or-v1-xxxxx)
OPENROUTER_API_KEY=sk-or-v1-YOUR_OPENROUTER_API_KEY_HERE

# Recommended models:
# - openai/gpt-4-turbo: Most capable (~$0.01/1K tokens)
# - openai/gpt-3.5-turbo: Fast and cheap (~$0.0005/1K tokens)
# - anthropic/claude-3-opus: Excellent reasoning (~$0.015/1K tokens)
# - mistralai/mistral-7b-instruct: Open source (~free)
# - meta-llama/llama-2-70b: Open source (~free)
OPENROUTER_MODEL=openai/gpt-3.5-turbo

# Your application domain (used for rate-limiting)
# Development: http://localhost:3000
# Production: https://yourdomain.com
OPENROUTER_REFERER=http://localhost:3000

# ============================================
# OLLAMA CONFIGURATION (LOCAL, FREE)
# ============================================
# Only required if AI_PROVIDER=ollama
#
# Ollama lets you run LLMs locally on your machine
# No API keys, no costs, complete privacy
#
# 1. Download: https://ollama.ai
# 2. Install and run: ollama serve
# 3. Pull a model: ollama pull llama2
#
# ‚ö†Ô∏è  Note: Requires significant RAM/GPU resources
# ‚ú® Benefits: Free, private, no rate limits
# üê¢ Downside: Slower than cloud APIs, requires local hardware

# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# Available models (run `ollama list` to see installed models):
# - llama2: General purpose (7B, 13B, 70B)
# - mistral: Lightweight and fast (~7B)
# - neural-chat: Good for conversations
# - openchat: Optimized for chat
# - phi: Tiny model suitable for CPU
OLLAMA_MODEL=llama2

# ============================================
# JWT CONFIGURATION (Optional - Future Auth)
# ============================================
# Secret key for JWT token signing
JWT_SECRET=your_jwt_secret_here_change_in_production

# JWT token expiration time (e.g., '7d', '24h', '60m')
JWT_EXPIRATION=7d

# ============================================
# LOGGING CONFIGURATION (Optional)
# ============================================
# Log level: debug, info, warn, error
LOG_LEVEL=debug

# ============================================
# QUICK SETUP GUIDE
# ============================================
# 1. Choose your AI provider (uncomment one):
#    - For testing with most models: AI_PROVIDER=openrouter
#    - For OpenAI direct: AI_PROVIDER=openai
#    - For local: AI_PROVIDER=ollama + start Ollama
#
# 2. Set up database (PostgreSQL):
#    createdb ai_growth_planner
#
# 3. Set required variables for your chosen provider
#
# 4. Run: npm install && npm run start:dev
#
# 5. Verify at: http://localhost:3000/api/docs (Swagger)

# ============================================
# JWT CONFIGURATION (Optional for future auth)
# ============================================
JWT_SECRET=your_jwt_secret_key_here
JWT_EXPIRATION=7d

# ============================================
# APPLICATION CONFIGURATION
# ============================================
APP_NAME=AI Growth Planner
APP_VERSION=1.0.0
APP_URL=http://localhost:3000
